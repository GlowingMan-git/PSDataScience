{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"3\" color=\"black\">\n",
    "    <div align=\"center\">\n",
    "        <h2>Tecnológico de Monterrey<br>\n",
    "            Campus Santa Fe<br><br>\n",
    "            Mathematics and Data Science for Decision Making<br>\n",
    "            Saúl Juárez Ordóñez (sauljz@tec.mx)<br><br>\n",
    "            <center>Principal Component Analysis</center>\n",
    "        </h2>\n",
    "    </div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"matrix3.jpg\" alt=\"Matrix\" style=\"display: block;margin-left:auto;margin-right: auto;width:70%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"blue\">\n",
    "<div align=\"justify\">\n",
    "<h1> Name and Student id:\n",
    "</h1>     \n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2>In this notebook we study the Principal Component Analysis technique and we will use it to help an anonymous company establish a classification among its collaborators. For that, the organization has provided a data set with several numerical indicators, which we are going to combine and establish the performance of each collaborator.<br><br> First we import all the necessary libraries.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Algebra\n",
    "import numpy as np\n",
    "#from numpy.random import randint\n",
    "#import random\n",
    "#import math\n",
    "#import sympy\n",
    "#from sympy import symbols, Eq, solve\n",
    "# Latex:\n",
    "#sympy.init_printing(use_latex = 'mathjax')\n",
    "#from random import randint\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd \n",
    "\n",
    "# Data visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h1>Data Exploration</h1>\n",
    "<h2>Secondly, we explore tha data set \"data_HR.csv\" from the human resources department of an anonymous organization.<br><br> <font color=\"blue\">Task: Import the file and call it \"df\" as in <i>dataframe</i>.</font></h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hum_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"blue\">\n",
    "<div align=\"justify\">\n",
    "<h2>Task: How many data points and variables do we have?</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "print('This dataset has {} rows and {} columns. The variables are:\\n\\n {}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"blue\">\n",
    "<div align=\"justify\">\n",
    "<h2>Task: Take a sample of size 10.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"blue\">\n",
    "<div align=\"justify\">\n",
    "<h2>Task: How many departments are there in this organization and which are they?</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"blue\">\n",
    "<div align=\"justify\">\n",
    "<h2>Task: What type of salaries do we have in this dataset?</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"blue\">\n",
    "<div align=\"justify\">\n",
    "<h2>Task: Get the descriptive statistics and interpret.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"blue\">\n",
    "<div align=\"justify\">\n",
    "<h2>Task: Get the correlation and interpret.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2>Let's visualize the correlation between variables with a heat map:</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.corr()\n",
    "f1 = plt.figure(figsize=(10,10))\n",
    "sns.heatmap(correlation, vmax=1, vmin=-1, square=True,annot=True,cmap='cubehelix')\n",
    "\n",
    "plt.title('Heatmap: Correlation between features\\n')\n",
    "f1.savefig('heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h1>Principal Component Analysis</h1>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2>Let's drop the non-numerical features \"id\", \"department\" and \"salary\".</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df.drop(labels=['id', 'department','salary'],axis=1)\n",
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2>Let's also rename the values of the column \"left\" since it is a label, say \"Yes\" for \"1\" and \"No\" for \"0\", and move it to the beginning.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop['left'].replace(0, 'No',inplace=True)\n",
    "df_drop['left'].replace(1, 'Yes',inplace=True)\n",
    "\n",
    "cols_d = df_drop.columns.tolist()\n",
    "cols_d.insert(0, cols_d.pop(cols_d.index('left')))\n",
    "df_drop = df_drop.reindex(columns = cols_d)\n",
    "\n",
    "df_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2>Now we extract all features in an array except \"left\" since it is not numerical.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_drop.iloc[:,1:8].values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h1> Standardization</h1>\n",
    "<h2>Not all the variables have the same units of measurement. Standardization is a variable scaling method with which we can obtain approximately normally distributed data with mean $0$ and standard deviation $1$. For each feature, we substract the mean to each observation and then we divide by the satndard deviation: $$ $$ $$z = \\frac{x-\\mu}{\\sigma}$$ We apply this to our numerical array $X$: </h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> And with the satndardized data we can construct the covariance matrix:</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.cov(X_std.T)\n",
    "cov_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> We can also construct the correlation  matrix from the non-standardized data $X$:</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.corrcoef(X.T)\n",
    "corr_mat\n",
    "# corr_mat_df = pd.DataFrame(corr_mat)\n",
    "# corr_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> We can also construct the correlation matrix from the standardized data $X$_std:</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_st = np.corrcoef(X_std.T)\n",
    "corr_mat_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> Now we find the eigenvectors and eigenvalues of the covariance matrix</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('Eigenvectors: \\n\\n%s' %eig_vecs)\n",
    "print('\\n Eigenvalues: \\n\\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> Note that the sum of the eigenvalues equals the number of eigenvectors:</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h1> Principal Components</h1>\n",
    "<h2>In order to decide which eigenvectors to keep and not lose too much information, we must observe the eigenvalues, the smaller ones carry within less information about the distribution of the data and therefore they can be cast aside.\n",
    "</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# ordering eigenpairs in ascending order\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print('Valores propios:/n')\n",
    "for i in eig_pairs:\n",
    "    print(i[0],i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> For example, the first component has a moderate positive association with \"last_evaluation\",\t\"number_project\"\tand \"average_montly_hours\", with $0.50695734,  0.5788351$ and $ 0.54901653$, respectively. The second component is strongly and positively related with \"satisfaction_level\" ($0.79$).\n",
    "</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h1> Explained variance</h1>\n",
    "<h2> The explained variance of a component tells us how much information (variance) can be attributed to this component. This is calculated by dividing the corresponding eigenvalue by the total sum of the eigenvalues. As a percentage, it is given by: \n",
    "</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "var_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> For example, the variance explained by the first three components is: \n",
    "</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_var = var_exp[0]+var_exp[1]+var_exp[2]\n",
    "sum_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> Let's visualize the individual explained variance:</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "\n",
    "    plt.bar(range(7), var_exp, alpha=0.5, align='center',\n",
    "            label='Individual explained variance')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> We can observe that the maximum variation of $26.14\\%$ can be explained by the first component and we can get rid of the last component since its explained variance is of $7.83\\%$.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> Now the accumulated variance</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(X_std)\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlim(0,7,1)\n",
    "    plt.xlabel('Componentes')\n",
    "    plt.ylabel('varianza acumulada explicada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2>The graph shows that above $90\\%$ of the variance is explained by the first six variables. Now we visualize our observations in a subspace of dimension $2$:</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "sklearn_pca = PCA(n_components=2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(data = Y_sklearn, columns = ['Componente Principal 1', 'Componente Principal 2'])\n",
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Componente Principal 1',fontsize=20)\n",
    "plt.ylabel('Componente Principal 2',fontsize=20)\n",
    "plt.title(\"Análisis de Componentes Principales\",fontsize=20)\n",
    "targets = ['Yes', 'No']\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = df_drop['left'] == target\n",
    "    plt.scatter(df_pca.loc[indicesToKeep, 'Componente Principal 1'], \n",
    "                df_pca.loc[indicesToKeep, 'Componente Principal 2'], c = color, s = 50)\n",
    "\n",
    "plt.legend(targets,prop={'size': 15})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h1> Projection matrix</h1>\n",
    "<h2>The projection matrix is the matrix formed with the eigenvectors that have the greatest eigenvalues.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(7,1), \n",
    "                      eig_pairs[1][1].reshape(7,1)\n",
    "                    ))\n",
    "print('Matrix W:\\n', matrix_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2>By multiplying the standardized matrix by the projection matrix we transform our data into a new space of variables.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X_std.dot(matrix_w)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2>Finally, we use the first principal component to assign a score to each collaborator and we merge the score column to the data set and we order it by scores.</h2>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X_std.dot(eig_vecs.T[0])\n",
    "Z_df = pd.DataFrame(Z)\n",
    "Z_df.columns = ['score']\n",
    "Z_df\n",
    "S = pd.merge(df,Z_df, right_index=True, left_index=True)\n",
    "S.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"times new roman\" size=\"2\" color=\"black\">\n",
    "<div align=\"justify\">\n",
    "<h2> Therefore, the top 5 collaborators are c810, c341, c14552, c12341 and c14877. Congratulations!</h2>\n",
    "</div>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}